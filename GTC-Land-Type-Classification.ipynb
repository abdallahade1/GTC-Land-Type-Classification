{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28782dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "# ---------------------------------------\n",
    "import os\n",
    "import shutil\n",
    "import hashlib\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80885ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define Paths\n",
    "# ---------------------------------------\n",
    "RAW_DATA_DIR = \"EuroSAT/2750\"       \n",
    "PROCESSED_DATA_DIR = \"data/processed\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c95aa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
      "AnnualCrop: 3000 images\n",
      "Forest: 3000 images\n",
      "HerbaceousVegetation: 3000 images\n",
      "Highway: 2500 images\n",
      "Industrial: 2500 images\n",
      "Pasture: 2000 images\n",
      "PermanentCrop: 2500 images\n",
      "Residential: 3000 images\n",
      "River: 2500 images\n",
      "SeaLake: 3000 images\n"
     ]
    }
   ],
   "source": [
    "# 3. Check Dataset Structure\n",
    "# ---------------------------------------\n",
    "classes = os.listdir(RAW_DATA_DIR)\n",
    "print(\"Classes found:\", classes)\n",
    "\n",
    "# Count images per class\n",
    "for cls in classes:\n",
    "    folder = os.path.join(RAW_DATA_DIR, cls)\n",
    "    print(f\"{cls}: {len(os.listdir(folder))} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5c6411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicates from AnnualCrop\n",
      "Removed 0 duplicates from Forest\n",
      "Removed 0 duplicates from HerbaceousVegetation\n",
      "Removed 0 duplicates from Highway\n",
      "Removed 0 duplicates from Industrial\n",
      "Removed 0 duplicates from Pasture\n",
      "Removed 0 duplicates from PermanentCrop\n",
      "Removed 0 duplicates from Residential\n",
      "Removed 0 duplicates from River\n",
      "Removed 0 duplicates from SeaLake\n",
      "Total duplicates removed: 0\n"
     ]
    }
   ],
   "source": [
    "# 4. Remove Duplicates\n",
    "# ---------------------------------------\n",
    "def remove_duplicates(folder):\n",
    "    hashes = {}\n",
    "    duplicates = []\n",
    "    \n",
    "    for img_name in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img_name)\n",
    "        try:\n",
    "            with open(img_path, \"rb\") as f:\n",
    "                filehash = hashlib.md5(f.read()).hexdigest()\n",
    "            if filehash in hashes:\n",
    "                duplicates.append(img_path)\n",
    "            else:\n",
    "                hashes[filehash] = img_path\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Remove duplicate images\n",
    "    for dup in duplicates:\n",
    "        os.remove(dup)\n",
    "    return len(duplicates)\n",
    "\n",
    "total_removed = 0\n",
    "for cls in classes:\n",
    "    folder = os.path.join(RAW_DATA_DIR, cls)\n",
    "    removed = remove_duplicates(folder)\n",
    "    total_removed += removed\n",
    "    print(f\"Removed {removed} duplicates from {cls}\")\n",
    "\n",
    "print(f\"Total duplicates removed: {total_removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f0554b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking EuroSAT/2750\\AnnualCrop: 100%|██████████| 3000/3000 [00:00<00:00, 12215.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 corrupted images from AnnualCrop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking EuroSAT/2750\\Forest: 100%|██████████| 3000/3000 [00:00<00:00, 12971.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 corrupted images from Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking EuroSAT/2750\\HerbaceousVegetation: 100%|██████████| 3000/3000 [00:00<00:00, 12742.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 corrupted images from HerbaceousVegetation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking EuroSAT/2750\\Highway: 100%|██████████| 2500/2500 [00:00<00:00, 13566.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 corrupted images from Highway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking EuroSAT/2750\\Industrial: 100%|██████████| 2500/2500 [00:00<00:00, 11955.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 corrupted images from Industrial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking EuroSAT/2750\\Pasture: 100%|██████████| 2000/2000 [00:00<00:00, 13265.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 corrupted images from Pasture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking EuroSAT/2750\\PermanentCrop: 100%|██████████| 2500/2500 [00:00<00:00, 12769.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 corrupted images from PermanentCrop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking EuroSAT/2750\\Residential: 100%|██████████| 3000/3000 [00:00<00:00, 12969.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 corrupted images from Residential\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking EuroSAT/2750\\River: 100%|██████████| 2500/2500 [00:00<00:00, 13482.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 corrupted images from River\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking EuroSAT/2750\\SeaLake: 100%|██████████| 3000/3000 [00:00<00:00, 13634.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 corrupted images from SeaLake\n",
      "Total corrupted removed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Check Corrupted Images\n",
    "# ---------------------------------------\n",
    "def check_and_clean_images(folder):\n",
    "    corrupted = []\n",
    "    for img_name in tqdm(os.listdir(folder), desc=f\"Checking {folder}\"):\n",
    "        img_path = os.path.join(folder, img_name)\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img.verify()  # Verify image integrity\n",
    "        except:\n",
    "            corrupted.append(img_path)\n",
    "            os.remove(img_path)\n",
    "    return corrupted\n",
    "\n",
    "corrupted_total = []\n",
    "for cls in classes:\n",
    "    folder = os.path.join(RAW_DATA_DIR, cls)\n",
    "    corrupted = check_and_clean_images(folder)\n",
    "    corrupted_total.extend(corrupted)\n",
    "    print(f\"Removed {len(corrupted)} corrupted images from {cls}\")\n",
    "\n",
    "print(f\"Total corrupted removed: {len(corrupted_total)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50691910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train/Val/Test split completed and copied to processed folder.\n"
     ]
    }
   ],
   "source": [
    "# 6. Split Train/Val/Test\n",
    "# ---------------------------------------\n",
    "def split_and_copy():\n",
    "    for cls in classes:\n",
    "        folder = os.path.join(RAW_DATA_DIR, cls)\n",
    "        images = os.listdir(folder)\n",
    "        \n",
    "        train_imgs, test_imgs = train_test_split(images, test_size=0.3, random_state=42)\n",
    "        val_imgs, test_imgs = train_test_split(test_imgs, test_size=0.5, random_state=42)\n",
    "        \n",
    "        splits = {\"train\": train_imgs, \"val\": val_imgs, \"test\": test_imgs}\n",
    "        \n",
    "        for split, split_imgs in splits.items():\n",
    "            split_dir = os.path.join(PROCESSED_DATA_DIR, split, cls)\n",
    "            os.makedirs(split_dir, exist_ok=True)\n",
    "            \n",
    "            for img_name in split_imgs:\n",
    "                src = os.path.join(folder, img_name)\n",
    "                dst = os.path.join(split_dir, img_name)\n",
    "                shutil.copy(src, dst)\n",
    "\n",
    "split_and_copy()\n",
    "print(\"✅ Train/Val/Test split completed and copied to processed folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36fbdedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset summary saved to data/dataset_summary.json\n"
     ]
    }
   ],
   "source": [
    "# 7. Save Dataset Summary\n",
    "# ---------------------------------------\n",
    "summary = {}\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    summary[split] = {}\n",
    "    for cls in classes:\n",
    "        folder = os.path.join(PROCESSED_DATA_DIR, split, cls)\n",
    "        count = len(os.listdir(folder))\n",
    "        summary[split][cls] = count\n",
    "\n",
    "with open(\"data/dataset_summary.json\", \"w\") as f:\n",
    "    json.dump(summary, f, indent=4)\n",
    "\n",
    "print(\"✅ Dataset summary saved to data/dataset_summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1cf39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
